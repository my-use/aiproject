import pickle
import uuid
from addition import addition_function
import pandas as pd
import streamlit as st
from dotenv import load_dotenv
from openai import OpenAI
from auth import register, login, logout
from common import get_llm_response
from life_functions import life_functions
from data_analysis import data_analysis
from shuju import create_chart

import os
from concurrent.futures import ThreadPoolExecutor
# from file_answer import get_answer
# å¯¼å…¥LangChainç›¸å…³ä¾èµ–
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.embeddings.openai import OpenAIEmbeddings
from langchain.chains.conversation.base import ConversationChain
from langchain.memory import ConversationBufferMemory
from langchain_openai import ChatOpenAI
from utils import dataframe_agent
from file_answer import get_answer

# é…ç½®æ–‡ä»¶è·¯å¾„
IMAGES_DIR = os.path.join(os.path.dirname(os.path.abspath(__file__)), "images")

# åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
def init_session_state():
    if 'logged_in_user' not in st.session_state:
        st.session_state.logged_in_user = None
    if 'chat_history' not in st.session_state:
        st.session_state.chat_history = []
    if 'general_memory' not in st.session_state:
        st.session_state.general_memory = ConversationBufferMemory(return_messages=True)
    if 'doc_memory' not in st.session_state:
        st.session_state.doc_memory = ConversationBufferMemory(return_messages=True)

# æ–‡ä»¶è§£æç›¸å…³é…ç½®
TEXT_SPLITTER = RecursiveCharacterTextSplitter(
    chunk_size=1000,
    chunk_overlap=200,
    length_function=len
)
EMBEDDINGS = OpenAIEmbeddings() if os.getenv("OPENAI_API_KEY") else None
VECTOR_STORE = None
FILE_HANDLED = False
executor = ThreadPoolExecutor(max_workers=4)




# é—®ç­”ç•Œé¢
def ask_question():
    mode = st.radio("é€‰æ‹©é—®ç­”æ¨¡å¼", ["ç›´æ¥æé—® ğŸ’¬", "æ–‡ä»¶æé—® ğŸ“","æ•°æ®å¤„ç† ğŸ“"])
    if mode == "æ–‡ä»¶æé—® ğŸ“":
        st.subheader("ğŸ“ æ–‡ä»¶ä¸Šä¼ ")
        if 'session_id' not in st.session_state:
            st.session_state['memory'] = ConversationBufferMemory(
                return_messages=True,
                memory_key='chat_history',
                output_key='answer'
            )
            st.session_state['session_id'] = uuid.uuid4().hex
            st.session_state['is_new_file'] = False
            with open('em.pkl', 'rb') as file_obj:
                em_model = pickle.load(file_obj)
                st.session_state['em_model'] = em_model

        uploaded_file = st.file_uploader('ä¸Šä¼ ä½ çš„æ–‡æœ¬æ–‡ä»¶ï¼š', type="txt")
        question = st.text_input('è¯·è¾“å…¥ä½ çš„é—®é¢˜', disabled=not uploaded_file)

        if uploaded_file:
            st.session_state['is_new_file'] = True
            with open(f'{st.session_state["session_id"]}.txt', 'w', encoding='utf-8') as temp_file:
                temp_file.write(uploaded_file.read().decode('utf-8'))

        if uploaded_file and question:
            response = get_answer(question)
            st.write('### ç­”æ¡ˆ')
            st.write(response['answer'])
            st.session_state['chat_history'] = response['chat_history']

        if 'chat_history' in st.session_state:
            with st.expander("å†å²æ¶ˆæ¯"):
                for i in range(0, len(st.session_state["chat_history"]), 2):
                    human_message = st.session_state["chat_history"][i]
                    ai_message = st.session_state["chat_history"][i + 1]
                    st.write(human_message.content)
                    st.write(ai_message.content)
                    if i < len(st.session_state["chat_history"]) - 2:
                        st.divider()
    if mode == "æ•°æ®å¤„ç† ğŸ“":
        option = st.radio("è¯·é€‰æ‹©æ•°æ®æ–‡ä»¶ç±»å‹:", ("Excel", "CSV"))
        file_type = "xlsx" if option == "Excel" else "csv"
        data = st.file_uploader(f"ä¸Šä¼ ä½ çš„{option}æ•°æ®æ–‡ä»¶", type=file_type)
        if data:
            if file_type == "xlsx":
                st.session_state["df"] = pd.read_excel(data, sheet_name='data')
            else:
                st.session_state["df"] = pd.read_csv(data)
            with st.expander("åŸå§‹æ•°æ®"):
                st.dataframe(st.session_state["df"])

        query = st.text_area(
            "è¯·è¾“å…¥ä½ å…³äºä»¥ä¸Šæ•°æ®é›†çš„é—®é¢˜æˆ–æ•°æ®å¯è§†åŒ–éœ€æ±‚ï¼š",
            disabled="df" not in st.session_state
        )
        button = st.button("ç”Ÿæˆå›ç­”")

        if button and "df" not in st.session_state:
            st.info("è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶")
            st.stop()
        if query:
            with st.spinner("AIæ­£åœ¨æ€è€ƒä¸­ï¼Œè¯·ç¨ç­‰..."):
                result = dataframe_agent(st.session_state["df"], query)
                if "answer" in result:
                    st.write(result["answer"])
                if "table" in result:
                    st.table(pd.DataFrame(result["table"]["data"],
                                          columns=result["table"]["columns"]))
                if "bar" in result:
                    create_chart(result["bar"], "bar")
                if "line" in result:
                    create_chart(result["line"], "line")
    if mode == "ç›´æ¥æé—® ğŸ’¬":
        def get_ai_response(user_prompt):
            model = ChatOpenAI(
                model='gpt-4o-mini',
                base_url='https://twapi.openai-hk.com/v1'
            )
            chain = ConversationChain(llm=model, memory=st.session_state['memory'])
            return chain.invoke({'input': user_prompt})['response']

        if 'messages' not in st.session_state:
            st.session_state['messages'] = [{'role': 'ai', 'content': 'ä½ å¥½ä¸»äººï¼Œæˆ‘æ˜¯ä½ çš„æ™ºèƒ½é—®ç­”åŠ©æ‰‹ï¼Œå¾ˆé«˜å…´ä¸ºä½ æœåŠ¡'}]
            st.session_state['memory'] = ConversationBufferMemory(return_message=True)

        for message in st.session_state['messages']:
            role, content = message['role'], message['content']
            st.chat_message(role).write(content)

        user_input = st.chat_input()
        if user_input:
            st.chat_message('human').write(user_input)
            st.session_state['messages'].append({'role': 'human', 'content': user_input})
            with st.spinner('AIæ­£åœ¨æ€è€ƒï¼Œè¯·ç­‰å¾…â€¦â€¦'):
                resp_from_ai = get_ai_response(user_input)
                st.session_state['history'] = resp_from_ai
                st.chat_message('ai').write(resp_from_ai)
                st.session_state['messages'].append({'role': 'ai', 'content': resp_from_ai})

# ä¸»å‡½æ•°
def main():
    init_session_state()
    # å±…ä¸­ä¸»æ ‡é¢˜ï¼ˆH1ï¼‰
    st.markdown("<h1 style='text-align: center;'>æ™ºèƒ½ä½“ç”Ÿæ´»ç®¡å®¶ âœ¨</h1>", unsafe_allow_html=True)

    # ä¾§è¾¹æ 
    if st.session_state.get('logged_in_user'):
        st.sidebar.write(f"ğŸ‘‹ æ¬¢è¿, {st.session_state.logged_in_user}")
        if st.sidebar.button("ç™»å‡º ğŸ”’", key="logout_button"):
            logout()

    # ç™»å½•/æ³¨å†Œç•Œé¢
    if st.session_state.get('logged_in_user') is None:
        # ä½¿ç”¨spanæ ‡ç­¾è‡ªå®šä¹‰æ ·å¼æ˜¾ç¤ºæç¤ºæ–‡æœ¬
        st.markdown("<span style='text-align: left; font-size: 1em; font-weight: normal;'>æ¬¢è¿ä½¿ç”¨æ™ºèƒ½ä½“ç”Ÿæ´»ç®¡å®¶ï¼è¯·å…ˆæ³¨å†Œæˆ–ç™»å½•ã€‚</span>", unsafe_allow_html=True)

        tab1, tab2 = st.tabs(["ç™»å½• ğŸ”‘","æ³¨å†Œ ğŸ“"])
        with tab1:
            login()
        with tab2:
            register()
    else:
        main_function = st.sidebar.selectbox(
            "é€‰æ‹©åŠŸèƒ½",
            ["æ™ºèƒ½é—®ç­”åŠ©æ‰‹ ğŸ’¡", "ç”Ÿæ´»æ•°æ®ç®¡ç† ğŸ ", "æ•°æ®åˆ†æ ğŸ“Š","å…¶ä»–åŠŸèƒ½ â­"]
        )
        if main_function == "æ™ºèƒ½é—®ç­”åŠ©æ‰‹ ğŸ’¡":
            ask_question()
        elif main_function == "ç”Ÿæ´»æ•°æ®ç®¡ç† ğŸ ":
            life_functions()
        elif main_function == "æ•°æ®åˆ†æ ğŸ“Š":
            data_analysis()
        elif main_function == "å…¶ä»–åŠŸèƒ½ â­":
            addition_function()

if __name__ == "__main__":
    main()